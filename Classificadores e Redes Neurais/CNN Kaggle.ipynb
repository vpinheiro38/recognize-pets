{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3Kaggle - CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "wBDcBg8NPsmf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from skimage import io, transform, util\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Activation, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.layers import Input, merge, ZeroPadding2D\n",
        "from keras.layers import AveragePooling2D, Concatenate, concatenate\n",
        "from keras.utils.io_utils import HDF5Matrix\n",
        "import keras.backend as K\n",
        "\n",
        "from keras import regularizers\n",
        "\n",
        "def openHDF5(filename):\n",
        "    return h5py.File(filename, \"a\")\n",
        "\n",
        "def readHDF5(fileName):\n",
        "    return h5py.File(fileName, 'r')\n",
        "  \n",
        "def getHDF5(file, name, qnt, init=0):\n",
        "    dset = file[name]\n",
        "    return dset[init:qnt]\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "    \n",
        "def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    \n",
        "def f1_score(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def makeYMat(qnt):\n",
        "    pets = ['cat', 'dog']\n",
        "    mat = []\n",
        "    for i in range(0, qnt):\n",
        "        for pet in pets:\n",
        "            if (pet == 'dog'):\n",
        "                mat.append(1)\n",
        "            else:\n",
        "                mat.append(0)   \n",
        "    return np.array(mat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qxxT_NBaPsmt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = \"\"\n",
        "\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive/')\n",
        "path = \"/content/drive/My Drive/datacnn/\"\n",
        "\n",
        "dsetTrain = readHDF5(path + 'imgsTrain100R.hdf5')\n",
        "dsetTest = readHDF5(path + 'imgsTest100R.hdf5')\n",
        "dsetValid = readHDF5(path + 'imgsValid100R.hdf5')\n",
        "\n",
        "qnt = 10000\n",
        "\n",
        "x_train = getHDF5(dsetTrain, 'pets', qnt)\n",
        "#x_test = getHDF5(dsetTest, 'pets', qnt, init=5000)\n",
        "#x_test2 = getHDF5(dsetTest, 'pets', 5000)\n",
        "x_testT = getHDF5(dsetTest, 'pets', 10000)\n",
        "#x_valid = getHDF5(dsetValid, 'pets', 1496)\n",
        "\n",
        "#x_train = np.append(x_train, x_test2, axis=0)\n",
        "y_train = makeYMat(15000//2)\n",
        "y_trainT = makeYMat(5000)\n",
        "y_test = makeYMat(5000//2)\n",
        "y_testT = makeYMat(5000)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "IMAGE_SIZE = 100\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT = IMAGE_SIZE, IMAGE_SIZE\n",
        "input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, 3)\n",
        "\n",
        "train_data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "valid_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "   \n",
        "#MATX_train = HDF5Matrix(path + 'imgsTrain100R.hdf5', 'pets')\n",
        "#MATX_test = HDF5Matrix(path + 'imgsTest100R.hdf5', 'pets')\n",
        "#MATX_valid = HDF5Matrix(path + 'imgsValid100R.hdf5', 'pets')\n",
        "\n",
        "seed = 0\n",
        "train_data_gen.fit(x_train, augment=True)\n",
        "\n",
        "train_gen = train_data_gen.flow(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seed=seed,\n",
        "    shuffle=True)\n",
        "\n",
        "test_gen = test_data_gen.flow(\n",
        "    x_test,\n",
        "    y_test,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seed=seed,\n",
        "    shuffle=True)\n",
        "\n",
        "valid_gen = valid_data_gen.flow(\n",
        "    x_valid,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False)\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "x_testT /= 255\n",
        "x_valid /= 255\n",
        "\n",
        "#from sklearn.utils import shuffle\n",
        "#x_train, y_train = shuffle(x_train, y_train, random_state=0)\n",
        "\n",
        "print(\"Matrix ready!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xe_cjMnLPsmz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(Conv2D(64, (3, 3), activation='linear', input_shape=input_shape))\n",
        "  model.add(Conv2D(64, (3, 3), activation='linear'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), activation='linear'))\n",
        "  model.add(Conv2D(128, (3, 3), activation='linear'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), activation='linear'))\n",
        "  model.add(Conv2D(256, (3, 3), activation='linear'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512, activation='linear', kernel_regularizer=regularizers.l2(0.004))) #Regularizer tirou invariancia do loss\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  model.add(Dense(512, activation='linear', kernel_regularizer=regularizers.l2(0.004))) # Activation linear possibilitou usar LR maior\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(1))\n",
        "  model.add(Activation('sigmoid')) #Sigmoid p/ binary\n",
        "\n",
        "  model.compile(optimizer=RMSprop(lr=0.0001), #LR Tirou a invariancia das metricas\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=[f1_score, 'accuracy', recall, precision])\n",
        "  print(\"Model Compiled\")\n",
        "\n",
        "  #print(model.summary())\n",
        "  model.load_weights(path + 'model16_weights.h5')\n",
        "  #history = model.fit(x_train, y_train, batch_size=64, epochs=100, verbose=1, validation_data=(x_test, y_test))\n",
        "  #history = model.fit_generator(train_gen, steps_per_epoch=15000//BATCH_SIZE, epochs=80, validation_data=test_gen, validation_steps=5000//BATCH_SIZE)\n",
        "  #print(\"Score Train: \" + str(model.evaluate(x_train, y_trainT, batch_size=64)))\n",
        "  print(\"Score Test: \"  + str(model.evaluate(x_testT, y_testT, batch_size=64)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_niq2RdVd-4f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BO_f9fM0LTen",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X_MpFDyaPsm4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "metrics = ['acc', 'loss', 'f1_score', 'precision', 'recall']\n",
        "\n",
        "i = 1\n",
        "for var in metrics:\n",
        "  plt.subplot(3,2,i)\n",
        "  plt.plot(history.history[var])\n",
        "  plt.plot(history.history['val_'+var])\n",
        "  plt.title('model '+var)\n",
        "  plt.ylabel(var)\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper right')\n",
        "  i += 1\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "pre_cls = model.predict(x_test)\n",
        "\n",
        "for i in range(5000):\n",
        "  if (pre_cls[i] > 0.5):\n",
        "    pre_cls[i] = 1\n",
        "  else:\n",
        "    pre_cls[i] = 0\n",
        "\n",
        "cm1 = confusion_matrix(y_test,pre_cls)\n",
        "print('Confusion Matrix : \\n', cm1)\n",
        "print('TP + TN: ', cm1[0][0]+cm1[1][1])\n",
        "print('FP + FN: ', cm1[0][1]+cm1[1][0])\n",
        "\n",
        "pre_cls = model.predict(x_valid)\n",
        "\n",
        "iDog = 0\n",
        "iCat = 0\n",
        "for i in range(1496):\n",
        "  if (pre_cls[i] > 0.5):\n",
        "    pre_cls[i] = 1\n",
        "    iDog += 1\n",
        "  else:\n",
        "    pre_cls[i] = 0\n",
        "    iCat += 1\n",
        "\n",
        "print('Qnt Cachorro: \\n', iDog)\n",
        "print('Qnt Gato: \\n', iCat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-GX1sPGRPsm8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model.save(path+'model16.h5')\n",
        "model.save_weights(path + 'model17_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7kWCXS-3r-oX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "clas = model\n",
        "clas.load_weights(path + 'model16_weights.h5')\n",
        "\n",
        "#history = clas.fit_generator(train_gen, steps_per_epoch=15000//BATCH_SIZE, epochs=100, validation_data=test_gen, validation_steps=5000//BATCH_SIZE)\n",
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "y_pred_keras = clas.predict(x_test)\n",
        "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)\n",
        "\n",
        "from sklearn.metrics import auc\n",
        "auc_keras = auc(fpr_keras, tpr_keras)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mR-j3Pg5qDnP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "  \n",
        "clas = model\n",
        "clas.load_weights(path + 'model16_weights.h5')\n",
        "\n",
        "img = image.img_to_array(x_train[3])\n",
        "img = img/255\n",
        "img = np.expand_dims(img, axis=0)\n",
        "\n",
        "layers = ['conv2d_63', 'conv2d_64', 'max_pooling2d_31']\n",
        "\n",
        "for layer in layers:\n",
        "  print(layer)\n",
        "  conv2d_output = Model(inputs=clas.input, outputs=clas.get_layer(layer).output)\n",
        "\n",
        "  conv2d_features = conv2d_output.predict(img)\n",
        "\n",
        "  fig = plt.figure(figsize=(14,7))\n",
        "  columns = 8\n",
        "  rows = 4\n",
        "  for i in range(columns*rows):\n",
        "      #img = mpimg.imread()\n",
        "      fig.add_subplot(rows, columns, i+1)\n",
        "      plt.axis('off')\n",
        "      plt.title('filter'+str(i))\n",
        "      plt.imshow(conv2d_features[0, :, :, i], cmap='gray')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WDRNj4Z8PsnA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ZuF-ak4PsnF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vTgNdwiT5TPG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "\n",
        "path2 = path+'validation'\n",
        "\n",
        "folder = os.fsencode(path2)\n",
        "\n",
        "filenames = []\n",
        "mylist = [['id', 'label']]\n",
        "\n",
        "i = 0\n",
        "for file in os.listdir(folder):\n",
        "  filename = os.fsdecode(file)\n",
        "  mylist.append([filename[:-4], str(int(pre_cls[i]))])\n",
        "  i += 1\n",
        "\n",
        "with open(path + 'submission5.csv', 'w') as myfile:\n",
        "     wr = csv.writer(myfile, quoting=csv.QUOTE_NONNUMERIC)\n",
        "     for item in mylist:\n",
        "         wr.writerow(item)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}